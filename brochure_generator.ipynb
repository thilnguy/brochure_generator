{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d9244069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cb198a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Ollama OpenAI client\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
    "ollama = OpenAI(base_url=OLLAMA_BASE_URL, api_key='ollama')\n",
    "\n",
    "USE_API = False  # Set to True to use OpenAI API instead of Ollama\n",
    "if USE_API:\n",
    "    load_dotenv()\n",
    "    OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "    openai = OpenAI()\n",
    "    GET_LINKS_RELEVANT_MODEL = \"gpt-4.1-mini\"\n",
    "    CREATE_BROCHURE_MODEL = \"gpt-4.1-mini\"\n",
    "else:\n",
    "    GET_LINKS_RELEVANT_MODEL = \"llama3.2\"\n",
    "    CREATE_BROCHURE_MODEL = \"gpt-oss\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2fe1a07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Ollama is running'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get(\"http://localhost:11434\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "01091cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# Standard headers to fetch a website\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "def fetch_website_contents(url):\n",
    "    \"\"\"\n",
    "    Return the title and contents of the website at the given url;\n",
    "    truncate to 2,000 characters as a sensible limit\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching the URL {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    title = soup.title.string if soup.title else \"No title found\"\n",
    "    if soup.body:\n",
    "        for body in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            body.decompose()\n",
    "        text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "    else:\n",
    "        text = \"\"\n",
    "    return (title + \"\\n\\n\" + text)[:2_000]\n",
    "    \n",
    "def fetch_website_links(url):\n",
    "    \"\"\"\n",
    "    Return the links on the webiste at the given url\n",
    "    I realize this is inefficient as we're parsing twice! This is to keep the code in the lab simple.\n",
    "    Feel free to use a class and optimize it!\n",
    "    \"\"\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    links = [link.get(\"href\") for link in soup.find_all(\"a\")]\n",
    "    return [link for link in links if link]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "70069c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define system and user prompts\n",
    "link_system_prompt = \"\"\"\n",
    "You are an expert web content analyzer. Your task is to identify and extract links from a given webpage that are most relevant to the main topic of the page. You are provided with a list of links found on a webpage. Provide only the URLs of the relevant links (such as About page, Company page, Careers/Jobs pages) to include in a brochure about the company without any additional commentary.\n",
    "You should return the links in a JSON array format as shown below:\n",
    "{\n",
    "    \"relevant_links\": [\n",
    "        {\"type: \"About page\", \"url\": \"https://example.com/about\"},\n",
    "        {\"type: \"Careers page\", \"url\": \"https://example.com/careers\"}\n",
    "    ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "def get_links_user_prompt(url):\n",
    "    user_prompt = f\"\"\"\n",
    "Here is the URL of the webpage: {url}\n",
    "Your task is to analyze the links on this page and identify those that are most relevant to the main topic of the page for inclusion in a company brochure.\n",
    "Please return the relevant links in the specified JSON format.\n",
    "Do not include Terms of Service, Privacy Policy, email links, or any other unrelated links.\n",
    "Links:\n",
    "\"\"\"\n",
    "    links = fetch_website_links(url)\n",
    "    user_prompt += \"\\n\".join(links)\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6da20fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_relevant_links(url):\n",
    "    \"\"\"\n",
    "    Select the relevant links to the url provided.\n",
    "    Args:\n",
    "        url (str): The url to select relevant links for.\n",
    "    Returns:\n",
    "        json: A list of relevant links in JSON format.\n",
    "    \"\"\"\n",
    "    if USE_API:\n",
    "        response = openai.chat.completions.create(\n",
    "            model=GET_LINKS_RELEVANT_MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": link_system_prompt},\n",
    "                {\"role\": \"user\", \"content\": get_links_user_prompt(url)}\n",
    "            ],\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "    else:\n",
    "        response = ollama.chat.completions.create(\n",
    "            model=GET_LINKS_RELEVANT_MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": link_system_prompt},\n",
    "                {\"role\": \"user\", \"content\": get_links_user_prompt(url)}\n",
    "            ],\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "    content = response.choices[0].message.content\n",
    "    try:\n",
    "        relevant_links = json.loads(content)\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Failed to parse JSON response: {content}\")\n",
    "        return []\n",
    "    return relevant_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c9163f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'relevant_links': [{'type': 'About page', 'url': 'https://huggingface.co'},\n",
       "  {'type': 'FAQs/Hub Documentation', 'url': '/docs'},\n",
       "  {'type': 'GitHub repository', 'url': 'https://github.com/huggingface'}]}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_relevant_links(\"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "430a4a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_page_and_relevant_links(url):\n",
    "    \"\"\"\n",
    "    Fetch the page content and relevant links for the given URL.\n",
    "    Args:\n",
    "        url (str): The URL of the webpage.\n",
    "    Returns:\n",
    "        str: The content of the webpage and relevant links.\n",
    "    \"\"\"\n",
    "    page_content = fetch_website_contents(url)\n",
    "    relevant_links = select_relevant_links(url)\n",
    "    \n",
    "    result = f\"## Webpage Content:\\n\\n{page_content}\\n\\n## Relevant Links:\\n\\n\"\n",
    "    for link in relevant_links.get(\"relevant_links\", []):\n",
    "        result += f\"Link: {link['type']}\\n\"\n",
    "        result += fetch_website_contents(link['url'])\n",
    "        result += \"\\n\\n\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d6790c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching the URL https://join.huggingface.co: HTTPSConnectionPool(host='join.huggingface.co', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x116bb2de0>: Failed to resolve 'join.huggingface.co' ([Errno 8] nodename nor servname provided, or not known)\"))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"NoneType\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[70]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mfetch_page_and_relevant_links\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhttps://huggingface.co\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[69]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mfetch_page_and_relevant_links\u001b[39m\u001b[34m(url)\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m link \u001b[38;5;129;01min\u001b[39;00m relevant_links.get(\u001b[33m\"\u001b[39m\u001b[33mrelevant_links\u001b[39m\u001b[33m\"\u001b[39m, []):\n\u001b[32m     14\u001b[39m     result += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLink: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlink[\u001b[33m'\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     \u001b[43mresult\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetch_website_contents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlink\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43murl\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m     result += \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[31mTypeError\u001b[39m: can only concatenate str (not \"NoneType\") to str"
     ]
    }
   ],
   "source": [
    "fetch_page_and_relevant_links(\"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf56f795",
   "metadata": {},
   "outputs": [],
   "source": [
    "brochure_system_prompt = \"\"\"\n",
    "You are a skilled brochure writer. Your task is to create a compelling brochure for a company based on the provided webpage content and relevant links. Use the information to highlight the company's strengths, values, and offerings in an engaging manner.\n",
    "The brochure should be well-structured, informative, and persuasive, aiming to attract potential customers or clients.\n",
    "Respond in markdown format without code blocks.\n",
    "Include sections such as Introduction, About Us, Services/Products, Careers, and Contact Information where applicable.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db56f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_brochure_user_prompt(company_name, url):\n",
    "    user_prompt = f\"\"\"\n",
    "    You are to create a brochure for {company_name}.\n",
    "    Using the following webpage content and relevant links, create a compelling brochure for the company.\n",
    "    Ensure the brochure is well-structured and highlights the company's strengths, values, and offerings.\n",
    "    Use this information to build a short brochure of the company in markdown format without code blocks.\n",
    "    \"\"\"\n",
    "    user_prompt += fetch_page_and_relevant_links(url)\n",
    "    return user_prompt[:5000]  # Truncate to first 5000 characters to fit model context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c992d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_brochure(company_name, url):\n",
    "    \"\"\"\n",
    "    Create a brochure for the given company using its webpage content and relevant links.\n",
    "    Args:\n",
    "        company_name (str): The name of the company.\n",
    "        url (str): The URL of the company's webpage.\n",
    "    Returns:\n",
    "        str: The generated brochure in markdown format.\n",
    "    \"\"\"\n",
    "    if USE_API:\n",
    "        response = openai.chat.completions.create(\n",
    "            model=CREATE_BROCHURE_MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": brochure_system_prompt},\n",
    "                {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        response = ollama.chat.completions.create(\n",
    "            model=CREATE_BROCHURE_MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": brochure_system_prompt},\n",
    "                {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
    "            ]\n",
    "        )\n",
    "    brochure = response.choices[0].message.content\n",
    "    display(Markdown(brochure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776daf32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Hugging Face â€“ The AI community building the future  \n",
       "\n",
       "Welcome to the worldâ€‘wide hub where researchers, engineers, and creators turn ideas into AI realities. Hugging Face is the openâ€‘source platform that empowers collaboration, acceleration, and innovation across every modalityâ€”from text and image to video, audio, and 3D.\n",
       "\n",
       "---\n",
       "\n",
       "## About Us  \n",
       "\n",
       "- **Mission**: Democratize AI by providing an inclusive, open ecosystem where anyone can host, share, and build upon stateâ€‘ofâ€‘theâ€‘art models, datasets, and applications.  \n",
       "- **Reach**: Over **1â€¯M+ publicly shared models**, **400k+ AI apps**, and **250k+ datasets** are available right now, continually growing with community contributions.  \n",
       "- **Philosophy**: Open source, transparency, and speed. All core libraries, tooling, and infrastructure are open, making it easy to move from research to production without friction.  \n",
       "\n",
       "---\n",
       "\n",
       "## What We Offer  \n",
       "\n",
       "### 1. **Model Hub**  \n",
       "- Host & version **unlimited** public (or private) models.  \n",
       "- Explore trending models such as *WeiboAI/VibeThinkerâ€‘1.5B*, *moonshotai/Kimiâ€‘K2â€‘Thinking*, and *facebook/sam3*.  \n",
       "- Seamless integration with ðŸ¤— Transformers, ðŸ¤— Diffusers, and other cuttingâ€‘edge libraries.  \n",
       "\n",
       "### 2. **Data Hub**  \n",
       "- Discover and share **250k+ datasets** across NLP, vision, audio, and more.  \n",
       "- Example datasets: *tensonaut/EPSTEIN_FILES_20K*, *nvidia/PhysicalAIâ€‘Autonomousâ€‘Vehicles*.  \n",
       "\n",
       "### 3. **Spaces** (AI Apps)  \n",
       "- Deploy, collaborate on, and try out **400k+ live applications** with instant inference.  \n",
       "- Trending Spaces: *Qwen Image Edit Camera Control*, *The Smol Training Playbook*, *Depth Anything 3*.  \n",
       "- Run on Zeroâ€‘Code, CPU, or GPUâ€‘accelerated (MCP) environments without provisioning infrastructure.  \n",
       "\n",
       "### 4. **Compute & Enterprise**  \n",
       "- **Paid compute services**: Scale up inference and training with onâ€‘demand GPU clusters.  \n",
       "- **Enterprise solutions**: Custom hosting, data privacy, dedicated support, and deploymentâ€‘ready AI pipelines.  \n",
       "\n",
       "---\n",
       "\n",
       "## Why Choose Hugging Face  \n",
       "\n",
       "| Value | What It Looks Like |\n",
       "|-------|--------------------|\n",
       "| **Speed** | Move from idea to demo in days, not months. |\n",
       "| **Multimodality** | Support for text, image, video, audio, 3D â€“ all in the same framework. |\n",
       "| **Collaboration** | Public Gitâ€‘like repos, community discussions, and realâ€‘time feedback. |\n",
       "| **Openâ€‘Source Stack** | No vendor lockâ€‘in; you own your models, data, and code. |\n",
       "| **Community** | Millions of researchers, developers, and companies contributing every day. |\n",
       "\n",
       "---\n",
       "\n",
       "## Careers  \n",
       "\n",
       "Join a team thatâ€™s reshaping AI for good. Hugging Face looks for passionate, creative minds in engineering, research, product, and operations.  \n",
       "- **Current open positions**: Visit the [Careers page](https://huggingface.co/jobs).  \n",
       "- **Culture**: Diverse, inclusive, & collaborative.  \n",
       "\n",
       "---\n",
       "\n",
       "## Get in Touch  \n",
       "\n",
       "- **Website**: [huggingface.co](https://huggingface.co)  \n",
       "- **LinkedIn**: [Hugging Face on LinkedIn](https://www.linkedin.com/company/huggingface)  \n",
       "- **Email**: contact@huggingface.co (general inquiries)  \n",
       "- **Support**: docs & community forums at [docs.huggingface.co](https://huggingface.co/docs).\n",
       "\n",
       "Ready to build, share, and accelerate your AI projects?  \n",
       "**[Sign Up Now](https://huggingface.co/signup)** â€“ the future starts with the first model you publish."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_brochure(\"Hugging Face\", \"https://huggingface.co\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-engineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
